{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def image_directory_to_pandas(image_path):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame with image paths and taxonomic labels extracted from a directory structure.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    image_path : str\n",
    "        The root directory containing subfolders with images.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing image paths and label information. Columns include:\n",
    "        - 'path': The full path to the image.\n",
    "        - 'folder_label': The folder name, representing the original label (format: 'family_genus_species').\n",
    "        - 'family': Extracted family name from the folder label.\n",
    "        - 'genus': Extracted genus name from the folder label.\n",
    "        - 'species': Combination of genus and species names (e.g., 'genus species').\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    ValueError:\n",
    "        If the folder label format does not match the expected 'family_genus_species' format.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    paths = []\n",
    "\n",
    "    # Walk through the directory and collect image paths and labels\n",
    "    for root_dir, _, filenames in os.walk(image_path):\n",
    "        for filename in filenames:\n",
    "            # Ignore hidden files and non-image files\n",
    "            if filename.startswith('.') or os.path.splitext(filename)[1].lower() not in {\".jpeg\", \".png\", \".jpg\"}:\n",
    "                continue\n",
    "\n",
    "            # Extract the folder name as the label, ignoring 'GT' directories\n",
    "            folder_label = os.path.basename(root_dir)\n",
    "            if folder_label != \"GT\":\n",
    "                labels.append(folder_label)\n",
    "                paths.append(os.path.join(root_dir, filename))\n",
    "\n",
    "    # Create DataFrame with paths and folder labels\n",
    "    df = pd.DataFrame({'image_path': paths, 'folder_label': labels})\n",
    "    df['folder_label'] = df['folder_label'].astype(\"category\")\n",
    "\n",
    "    # Split the folder_label into 'family', 'genus', and 'species'\n",
    "    try:\n",
    "        df[['family', 'genus', 'species']] = df['folder_label'].str.split(\"_\", expand=True)\n",
    "        df['species'] = df['genus'] + \" \" + df['species']\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            \"Error splitting folder labels. Ensure that your folder structure follows 'family_genus_species' format.\"\n",
    "        ) from e\n",
    "\n",
    "    # Return the dataframe with specified columns\n",
    "    return df[['image_path', 'folder_label', 'family', 'genus', 'species']]\n",
    "\n",
    "def split_image_dataframe(df, test_size=0.2, val_size=0.1, random_state=42, stratify_by='folder_label'):\n",
    "    \"\"\"\n",
    "    Split a pandas DataFrame into train, validation, and test sets,\n",
    "    stratified by the 'folder_name' column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing image paths and labels.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        val_size (float): Proportion of the dataset to include in the validation split.\n",
    "        random_state (int): Seed for random number generation for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three pandas DataFrames for train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    # First, split into train+validation and test sets\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        stratify=df[stratify_by],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Calculate the adjusted validation size relative to the remaining train+val data\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "    \n",
    "    # Split the train+validation set into train and validation sets\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=val_relative_size,\n",
    "        stratify=train_val_df[stratify_by],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def process_image_and_labels(image_path, family, genus, species, family_labels, genus_labels, species_labels, image_size=(224,224)):\n",
    "    \"\"\"\n",
    "    Process an image and its corresponding labels for training.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    image_path : str\n",
    "        The path to the image file.\n",
    "    family : str\n",
    "        The family label of the image.\n",
    "    genus : str\n",
    "        The genus label of the image.\n",
    "    species : str\n",
    "        The species label of the image.\n",
    "    family_labels : tf.Tensor\n",
    "        Tensor of unique family labels.\n",
    "    genus_labels : tf.Tensor\n",
    "        Tensor of unique genus labels.\n",
    "    species_labels : tf.Tensor\n",
    "        Tensor of unique species labels.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    img : tf.Tensor\n",
    "        The processed image tensor.\n",
    "    labels : dict\n",
    "        A dictionary containing one-hot encoded labels for family, genus, and species.\n",
    "    \"\"\"\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(image_path)\n",
    "    # Decode the image\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    img = tf.image.resize(img, image_size)\n",
    "\n",
    "    # Convert family, genus, and species to indices\n",
    "    family_label = tf.argmax(tf.equal(family_labels, family))\n",
    "    genus_label = tf.argmax(tf.equal(genus_labels, genus))\n",
    "    species_label = tf.argmax(tf.equal(species_labels, species))\n",
    "\n",
    "    # Convert to one-hot encoded format\n",
    "    family_label = tf.one_hot(family_label, len(family_labels))\n",
    "    genus_label = tf.one_hot(genus_label, len(genus_labels))\n",
    "    species_label = tf.one_hot(species_label, len(species_labels))\n",
    "\n",
    "    # Return the image and a dictionary of labels with matching keys\n",
    "    return img, {\n",
    "        \"family\": family_label,\n",
    "        \"genus\": genus_label,\n",
    "        \"species\": species_label\n",
    "    }\n",
    "\n",
    "def build_dataset_from_dataframe(df, batch_size=32, image_size=(224,224)):\n",
    "    \"\"\"\n",
    "    Build a TensorFlow dataset from a DataFrame containing image paths and taxonomic labels.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the following columns:\n",
    "        - 'path': The path to the image.\n",
    "        - 'Family': The family label of the image.\n",
    "        - 'Genus': The genus label of the image.\n",
    "        - 'Species': The species label of the image.\n",
    "    batch_size : int, optional\n",
    "        Batch size for training. Default is 32.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    image_label_ds : tf.data.Dataset\n",
    "        A TensorFlow dataset with images and one-hot encoded labels.\n",
    "    family_labels : list\n",
    "        A sorted list of unique family labels.\n",
    "    genus_labels : list\n",
    "        A sorted list of unique genus labels.\n",
    "    species_labels : list\n",
    "        A sorted list of unique species labels.\n",
    "    \"\"\"\n",
    "    # Extract the unique family, genus, and species from the dataframe\n",
    "    family_labels = sorted(df['family'].unique())\n",
    "    genus_labels = sorted(df['genus'].unique())\n",
    "    species_labels = sorted(df['species'].unique())\n",
    "\n",
    "    # Convert family, genus, and species labels to TensorFlow tensors\n",
    "    family_labels = tf.constant(family_labels)\n",
    "    genus_labels = tf.constant(genus_labels)\n",
    "    species_labels = tf.constant(species_labels)\n",
    "\n",
    "    # Create a TensorFlow dataset from the dataframe's paths and labels\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (df['image_path'].values, df['family'].values, df['genus'].values, df['species'].values)\n",
    "    )\n",
    "\n",
    "    # Map the processing function to the dataset\n",
    "    image_label_ds = path_ds.map(\n",
    "        lambda path, family, genus, species: process_image_and_labels(\n",
    "            path, family, genus, species, family_labels, genus_labels, species_labels, image_size=image_size\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Shuffle, batch, and prefetch the dataset\n",
    "    image_label_ds = image_label_ds.shuffle(buffer_size=len(df))\n",
    "    image_label_ds = image_label_ds.batch(batch_size)\n",
    "    image_label_ds = image_label_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return (\n",
    "        image_label_ds,\n",
    "        family_labels.numpy().tolist(),\n",
    "        genus_labels.numpy().tolist(),\n",
    "        species_labels.numpy().tolist(),\n",
    "    )\n",
    "\n",
    "def predict_image(image_path, model, family_labels, genus_labels, species_labels, image_size=(224,224) ,top_k=3):\n",
    "    \"\"\"\n",
    "    Predict the top-k family, genus, and species from an image using a trained model,\n",
    "    and display the image with predictions.\n",
    "\n",
    "    Args:\n",
    "    - image_path (str): Path to the image file.\n",
    "    - model (tf.keras.Model): The trained model.\n",
    "    - family_labels (list): List of family labels.\n",
    "    - genus_labels (list): List of genus labels.\n",
    "    - species_labels (list): List of species labels.\n",
    "    - top_k (int): Number of top predictions to return.\n",
    "\n",
    "    Returns:\n",
    "    - top_k_family: List of tuples (family, confidence) for top k family predictions.\n",
    "    - top_k_genus: List of tuples (genus, confidence) for top k genus predictions.\n",
    "    - top_k_species: List of tuples (species, confidence) for top k species predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, image_size)\n",
    "    img = tf.expand_dims(img, 0)  # Add batch dimension\n",
    "\n",
    "    # Predict family, genus, and species\n",
    "    family_pred, genus_preds, species_preds = model.predict(img)\n",
    "    \n",
    "    # Get top-k predictions for family\n",
    "    top_k_family_indices = np.argsort(family_pred[0])[-top_k:][::-1]\n",
    "    top_k_family = [(family_labels[i], family_pred[0][i]) for i in top_k_family_indices]\n",
    "\n",
    "    # Get top-k predictions for genus\n",
    "    top_k_genus_indices = np.argsort(genus_preds[0])[-top_k:][::-1]\n",
    "    top_k_genus = [(genus_labels[i], genus_preds[0][i]) for i in top_k_genus_indices]\n",
    "\n",
    "    # Get top-k predictions for species\n",
    "    top_k_species_indices = np.argsort(species_preds[0])[-top_k:][::-1]\n",
    "    top_k_species = [(species_labels[i], species_preds[0][i]) for i in top_k_species_indices]\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(tf.image.resize(img[0], image_size) / 255.0)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print top-k predictions for each level\n",
    "    print(\"Top 3 Family Predictions:\")\n",
    "    for family, confidence in top_k_family:\n",
    "        print(f\"{family}: {confidence:.4f}\")\n",
    "\n",
    "    print(\"\\nTop 3 Genus Predictions:\")\n",
    "    for genus, confidence in top_k_genus:\n",
    "        print(f\"{genus}: {confidence:.4f}\")\n",
    "\n",
    "    print(\"\\nTop 3 Species Predictions:\")\n",
    "    for species, confidence in top_k_species:\n",
    "        print(f\"{species}: {confidence:.4f}\")\n",
    "\n",
    "    return top_k_family, top_k_genus, top_k_species\n",
    "\n",
    "def plot_training_history(history, history_fine, fine_tune_at):\n",
    "    \"\"\"\n",
    "    Plot the training history of accuracy and loss for each output.\n",
    "    \n",
    "    Args:\n",
    "    - history (History): History object from the initial training.\n",
    "    - history_fine (History): History object from the fine-tuning phase.\n",
    "    - fine_tune_at (int): Epoch at which fine-tuning began.\n",
    "    \"\"\"\n",
    "    # Combine initial training history and fine-tuning history\n",
    "    accuracy_keys = ['family_accuracy', 'genus_accuracy', 'species_accuracy']\n",
    "    val_accuracy_keys = ['val_family_accuracy', 'val_genus_accuracy', 'val_species_accuracy']\n",
    "    loss_keys = ['family_loss', 'genus_loss', 'species_loss']\n",
    "    val_loss_keys = ['val_family_loss', 'val_genus_loss', 'val_species_loss']\n",
    "\n",
    "    # Combine the data from the initial training and fine-tuning phases\n",
    "    combined_history = {}\n",
    "    for key in accuracy_keys + val_accuracy_keys + loss_keys + val_loss_keys:\n",
    "        combined_history[key] = history.history.get(key, []) + history_fine.history.get(key, [])\n",
    "\n",
    "    total_epochs = len(combined_history[accuracy_keys[0]])  # Total number of epochs including fine-tuning\n",
    "    \n",
    "    # Create subplots for accuracy and loss\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Plot accuracy for each output\n",
    "    for idx, key in enumerate(accuracy_keys):\n",
    "        axs[0, idx].plot(combined_history[key], label='Training Accuracy')\n",
    "        axs[0, idx].plot(combined_history[val_accuracy_keys[idx]], label='Validation Accuracy')\n",
    "        axs[0, idx].axvline(x=fine_tune_at, color='r', linestyle='--', label='Fine-Tuning Start')\n",
    "        axs[0, idx].set_title(f'{key.replace(\"_accuracy\", \"\").capitalize()} Accuracy')\n",
    "        axs[0, idx].set_xlabel('Epochs')\n",
    "        axs[0, idx].set_ylabel('Accuracy')\n",
    "        axs[0, idx].legend()\n",
    "        axs[0, idx].grid(True)\n",
    "    \n",
    "    # Plot loss for each output\n",
    "    for idx, key in enumerate(loss_keys):\n",
    "        axs[1, idx].plot(combined_history[key], label='Training Loss')\n",
    "        axs[1, idx].plot(combined_history[val_loss_keys[idx]], label='Validation Loss')\n",
    "        axs[1, idx].axvline(x=fine_tune_at, color='r', linestyle='--', label='Fine-Tuning Start')\n",
    "        axs[1, idx].set_title(f'{key.replace(\"_loss\", \"\").capitalize()} Loss')\n",
    "        axs[1, idx].set_xlabel('Epochs')\n",
    "        axs[1, idx].set_ylabel('Loss')\n",
    "        axs[1, idx].legend()\n",
    "        axs[1, idx].grid(True)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "settings = dict(\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    ftun_epochs = 10,\n",
    "    img_size = (128, 128),\n",
    "    seed = 42,\n",
    "    ftun_last_layers = 70,\n",
    "    ftune_learning_rate = 0.00001,\n",
    "    \n",
    ")\n",
    "\n",
    "df = image_directory_to_pandas(\"/Users/leonardo/Documents/Projects/cryptovision/data/processed/cv_images_dataset\")\n",
    "\n",
    "train_df, val_df, test_df = split_image_dataframe(df, test_size=0.15, val_size=0.15, stratify_by='folder_label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been copied to /Users/leonardo/Library/CloudStorage/Box-Box/CryptoVision/Data/crypto_id_trivia in subfolders by label\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def stratified_sample_and_copy_by_label(df, samples_per_label, dest_path):\n",
    "    # Load the dataset\n",
    "    #df = pd.read_csv(df_path)\n",
    "    \n",
    "    # Create the destination directory if it doesn't exist\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "    \n",
    "    # Loop through each unique folder_label and select samples\n",
    "    for label in df['folder_label'].unique():\n",
    "        # Filter the dataset for the current label\n",
    "        label_df = df[df['folder_label'] == label]\n",
    "        \n",
    "        # Check if there are enough samples for the given label\n",
    "        if len(label_df) < samples_per_label:\n",
    "            print(f\"Warning: Not enough samples for label '{label}' (requested {samples_per_label}, available {len(label_df)})\")\n",
    "            sampled_df = label_df  # Use all available samples\n",
    "        else:\n",
    "            # Randomly select samples_per_label from this subset\n",
    "            sampled_df = label_df.sample(n=samples_per_label, random_state=42)\n",
    "        \n",
    "        # Create a subfolder for the current label in the destination directory\n",
    "        label_dest_path = os.path.join(dest_path, str(label))\n",
    "        os.makedirs(label_dest_path, exist_ok=True)\n",
    "        \n",
    "        # Copy each selected image to the label-specific subfolder\n",
    "        for _, row in sampled_df.iterrows():\n",
    "            src_image_path = row['image_path']\n",
    "            filename = os.path.basename(src_image_path)  # Preserves original file extension\n",
    "            dest_image_path = os.path.join(label_dest_path, filename)\n",
    "            \n",
    "            # Copy the file\n",
    "            shutil.copy2(src_image_path, dest_image_path)\n",
    "    \n",
    "    print(f\"Images have been copied to {dest_path} in subfolders by label\")\n",
    "\n",
    "# Example usage\n",
    "df_path = 'path/to/your/dataset.csv'  # Path to your dataset CSV file\n",
    "samples_per_label = 4  # Number of samples per label\n",
    "dest_path = '/Users/leonardo/Library/CloudStorage/Box-Box/CryptoVision/Data/crypto_id_trivia'  # Path to where images should be copied\n",
    "\n",
    "stratified_sample_and_copy_by_label(df, samples_per_label, dest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

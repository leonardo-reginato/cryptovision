{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_observations(species_name, per_page=30, page=1):\n",
    "    \"\"\"\n",
    "    Fetch observations for a given species name from iNaturalist.\n",
    "    \"\"\"\n",
    "    url = \"https://api.inaturalist.org/v1/observations\"\n",
    "    params = {\n",
    "        \"q\": species_name,\n",
    "        \"per_page\": per_page,\n",
    "        \"page\": page,\n",
    "        \"photos\": True,\n",
    "        \"taxon_name\": species_name,\n",
    "        \"iconic_taxa\": \"Actinopterygii\"  # Ray-finned fishes\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    Download an image from a URL and save it to the specified path.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "    else:\n",
    "        print(f\"Failed to download image: {url}\")\n",
    "        \n",
    "def download_fish_images(species_name, download_dir, max_images=10):\n",
    "    \"\"\"\n",
    "    Download images of a specific fish species from iNaturalist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    observations = fetch_observations(species_name)\n",
    "    if not observations:\n",
    "        print(\"No observations found.\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "    for result in observations.get('results', []):\n",
    "        if count >= max_images:\n",
    "            break\n",
    "        for photo in result.get('photos', []):\n",
    "            image_url = photo.get('url')\n",
    "            if image_url:\n",
    "                # Construct the URL for the original-sized image\n",
    "                original_url = image_url.replace(\"square\", \"original\")\n",
    "                image_id = photo.get('id')\n",
    "                extension = original_url.split('.')[-1]\n",
    "                save_path = os.path.join(download_dir, f\"{species_name}_{image_id}.{extension}\")\n",
    "                download_image(original_url, save_path)\n",
    "                print(f\"Downloaded: {save_path}\")\n",
    "                count += 1\n",
    "                if count >= max_images:\n",
    "                    break\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Priolepis Dawsoni/Priolepis Dawsoni_19504470.jpg\n"
     ]
    }
   ],
   "source": [
    "species = \"Priolepis Dawsoni\"  # Replace with your target species name\n",
    "download_directory = f\"/Users/leonardo/Documents/Projects/cryptovision/data/raw/{species}\"  # Replace with your desired local path\n",
    "max_images_to_download = 1000  # Set the maximum number of images to download\n",
    "download_fish_images(species, download_directory, max_images_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_observations(taxon_name, rank, per_page=30, page=1):\n",
    "    \"\"\"\n",
    "    Fetch observations for a given taxon name and rank from iNaturalist.\n",
    "    \"\"\"\n",
    "    url = \"https://api.inaturalist.org/v1/observations\"\n",
    "    params = {\n",
    "        \"taxon_name\": taxon_name,\n",
    "        \"rank\": rank,\n",
    "        \"per_page\": per_page,\n",
    "        \"page\": page,\n",
    "        \"photos\": True\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "import os\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    Download an image from a URL and save it to the specified path.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "    else:\n",
    "        print(f\"Failed to download image: {url}\")\n",
    "        \n",
    "def download_taxon_images(taxon_name, rank, download_dir, max_images=10):\n",
    "    \"\"\"\n",
    "    Download images of a specific taxon (genus or family) from iNaturalist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    observations = fetch_observations(taxon_name, rank)\n",
    "    if not observations:\n",
    "        print(\"No observations found.\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "    for result in observations.get('results', []):\n",
    "        if count >= max_images:\n",
    "            break\n",
    "        for photo in result.get('photos', []):\n",
    "            image_url = photo.get('url')\n",
    "            if image_url:\n",
    "                # Construct the URL for the original-sized image\n",
    "                original_url = image_url.replace(\"square\", \"original\")\n",
    "                image_id = photo.get('id')\n",
    "                extension = original_url.split('.')[-1]\n",
    "                save_path = os.path.join(download_dir, f\"{taxon_name}_{image_id}.{extension}\")\n",
    "                download_image(original_url, save_path)\n",
    "                print(f\"Downloaded: {save_path}\")\n",
    "                count += 1\n",
    "                if count >= max_images:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_451856063.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_451800259.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_451728700.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_451728732.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_449358769.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_449358783.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_448583756.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_448583321.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484909.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484929.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484945.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484964.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484975.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447484985.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447485010.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_447045483.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_446451114.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_446451001.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_445637443.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_444208206.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_444208274.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_443357324.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_441240251.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_441240256.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_440228278.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_438575624.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_438523499.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_437937530.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_437939131.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_437444642.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_437309994.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_437310012.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_436134717.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_435725753.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_434502218.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_434502163.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_433809946.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_433809972.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_433809974.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_433757532.png\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_433686101.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_431851322.jpeg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_430617002.jpg\n",
      "Downloaded: /Users/leonardo/Documents/Projects/cryptovision/data/raw/Apogonidae/Apogonidae_430201109.jpg\n"
     ]
    }
   ],
   "source": [
    "taxon = \"Apogonidae\"  # Replace with your target genus or family name\n",
    "rank = \"family\"  # Specify the rank: 'genus' or 'family'\n",
    "download_directory = f\"/Users/leonardo/Documents/Projects/cryptovision/data/raw/{taxon}\"  # Replace with your desired local path\n",
    "max_images_to_download = 100  # Set the maximum number of images to download\n",
    "download_taxon_images(taxon, rank, download_directory, max_images_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 403\n",
      "No species found for the given genus.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_species_by_genus(genus_name):\n",
    "    \"\"\"\n",
    "    Fetch species data for a given genus from FishBase.\n",
    "    \"\"\"\n",
    "    url = f\"https://fishbase.ropensci.org/species\"\n",
    "    params = {\n",
    "        \"Genus\": genus_name\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "import os\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    Download an image from a URL and save it to the specified path.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "    else:\n",
    "        print(f\"Failed to download image: {url}\")\n",
    "        \n",
    "def download_genus_images(genus_name, download_dir, max_images_per_species=5):\n",
    "    \"\"\"\n",
    "    Download images of all species within a specific genus from FishBase.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    species_data = fetch_species_by_genus(genus_name)\n",
    "    if not species_data:\n",
    "        print(\"No species found for the given genus.\")\n",
    "        return\n",
    "\n",
    "    for species in species_data.get('data', []):\n",
    "        species_name = species.get('Species')\n",
    "        genus = species.get('Genus')\n",
    "        if species_name and genus:\n",
    "            full_species_name = f\"{genus} {species_name}\"\n",
    "            print(f\"Fetching images for {full_species_name}...\")\n",
    "            # Construct the URL to the species summary page\n",
    "            species_url = f\"https://www.fishbase.se/summary/{genus}-{species_name}.html\"\n",
    "            # Fetch the species summary page\n",
    "            response = requests.get(species_url)\n",
    "            if response.status_code == 200:\n",
    "                # Parse the page to find image URLs\n",
    "                from bs4 import BeautifulSoup\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                image_tags = soup.find_all('img')\n",
    "                count = 0\n",
    "                for img in image_tags:\n",
    "                    if count >= max_images_per_species:\n",
    "                        break\n",
    "                    img_url = img.get('src')\n",
    "                    if img_url and 'thumbnails' in img_url.lower():\n",
    "                        # Construct the full image URL\n",
    "                        img_url = img_url.replace('Thumbnails', 'Pictures')\n",
    "                        img_url = img_url.replace('tn_', '')\n",
    "                        if not img_url.startswith('http'):\n",
    "                            img_url = f\"https://www.fishbase.se{img_url}\"\n",
    "                        # Determine the image file name\n",
    "                        img_name = img_url.split('/')[-1]\n",
    "                        save_path = os.path.join(download_dir, img_name)\n",
    "                        # Download the image\n",
    "                        download_image(img_url, save_path)\n",
    "                        print(f\"Downloaded: {save_path}\")\n",
    "                        count += 1\n",
    "            else:\n",
    "                print(f\"Failed to fetch species page for {full_species_name}\")\n",
    "                \n",
    "genus = \"Eviota\"  # Replace with your target genus or family name\n",
    "rank = \"genus\"  # Specify the rank: 'genus' or 'family'\n",
    "download_directory = f\"/Users/leonardo/Documents/Projects/cryptovision/data/raw/fishbase/{genus}\"  # Replace with your desired local path\n",
    "max_images = 5  # Set the maximum number of images to download per species\n",
    "download_genus_images(genus, download_directory, max_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess images\n",
    "def load_images_and_labels(image_path, image_size=(224, 224)):\n",
    "    \"\"\"Load images and extract family, genus, and species labels from directory structure.\"\"\"\n",
    "    images, families, genera, species = [], [], [], []\n",
    "\n",
    "    for root, _, files in os.walk(image_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = Image.open(img_path).resize(image_size)\n",
    "                images.append(np.array(img))\n",
    "\n",
    "                # Extract labels from folder structure\n",
    "                folder_name = os.path.basename(root)\n",
    "                try:\n",
    "                    family, genus, specie = folder_name.split(\"_\")\n",
    "                except ValueError:\n",
    "                    raise ValueError(\n",
    "                        f\"Folder name '{folder_name}' does not follow 'family_genus_species' format.\"\n",
    "                    )\n",
    "                families.append(family)\n",
    "                genera.append(genus)\n",
    "                species.append(f\"{genus} {specie}\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = pd.DataFrame({\n",
    "        'family': families,\n",
    "        'genus': genera,\n",
    "        'species': species\n",
    "    })\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m image_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)  \u001b[38;5;66;03m# Adjust based on dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load images and labels\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mload_images_and_labels\u001b[0;34m(image_path, image_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      9\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file)\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(img))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Extract labels from folder structure\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvenv/lib/python3.10/site-packages/PIL/Image.py:2222\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2212\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2213\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2214\u001b[0m         )\n\u001b[1;32m   2215\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2216\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2217\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2218\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2219\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2220\u001b[0m         )\n\u001b[0;32m-> 2222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example dataset path\n",
    "data_path = \"/Users/leonardo/Library/CloudStorage/Box-Box/CryptoVision/Data/fish_functions/Species_v03\"  # Replace with actual path\n",
    "image_size = (64, 64)  # Adjust based on dataset\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images_and_labels(data_path, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoders = {}\n",
    "encoded_labels = {}\n",
    "for level in ['family', 'genus', 'species']:\n",
    "    label_encoders[level] = {label: idx for idx, label in enumerate(sorted(labels[level].unique()))}\n",
    "    encoded_labels[level] = labels[level].map(label_encoders[level]).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images.reshape(len(images), -1),\n",
    "    np.column_stack([encoded_labels[level] for level in ['family', 'genus', 'species']]),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=encoded_labels['species']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DummyClassifier for family level\n",
      "Accuracy: 0.1153\n",
      "Precision: 0.1130\n",
      "Recall: 0.1153\n",
      "F1 Score: 0.1141\n",
      "\n",
      "Training DummyClassifier for genus level\n",
      "Accuracy: 0.0244\n",
      "Precision: 0.0245\n",
      "Recall: 0.0244\n",
      "F1 Score: 0.0243\n",
      "\n",
      "Training DummyClassifier for species level\n",
      "Accuracy: 0.0266\n",
      "Precision: 0.0269\n",
      "Recall: 0.0266\n",
      "F1 Score: 0.0266\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for i, level in enumerate(['family', 'genus', 'species']):\n",
    "    print(f\"\\nTraining DummyClassifier for {level} level\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "    dummy_clf.fit(X_train, y_train[:, i])\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test[:, i], y_pred)\n",
    "    precision = precision_score(y_test[:, i], y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_test[:, i], y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test[:, i], y_pred, average=\"weighted\")\n",
    "\n",
    "    # Store metrics\n",
    "    metrics[level] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Metrics:\n",
      "Family Level:\n",
      "  Accuracy: 0.1153\n",
      "  Precision: 0.1130\n",
      "  Recall: 0.1153\n",
      "  F1: 0.1141\n",
      "Genus Level:\n",
      "  Accuracy: 0.0244\n",
      "  Precision: 0.0245\n",
      "  Recall: 0.0244\n",
      "  F1: 0.0243\n",
      "Species Level:\n",
      "  Accuracy: 0.0266\n",
      "  Precision: 0.0269\n",
      "  Recall: 0.0266\n",
      "  F1: 0.0266\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOverall Metrics:\")\n",
    "for level, metric in metrics.items():\n",
    "    print(f\"{level.capitalize()} Level:\")\n",
    "    for metric_name, value in metric.items():\n",
    "        print(f\"  {metric_name.capitalize()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_path = '/Users/leonardo/Documents/Projects/cryptovision/data/processed/cv_images_dataset'\n",
    "new_path = '/Volumes/T7_shield/CryptoVision/Data/others/hemingson_reviewed'\n",
    "\n",
    "for folder in os.listdir(source_path):\n",
    "    if folder.startswith(\".\"):\n",
    "        continue\n",
    "    \n",
    "    os.makedirs(os.path.join(new_path, folder), exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

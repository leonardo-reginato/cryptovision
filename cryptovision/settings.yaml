# =====================================================
# Global Experiment Settings
# =====================================================

# General Configuration
project_name: "CVisionClassifier"  # Project name (used for wandb and directory organization)
experiment_name: null       # Name of the experiment run or None
tags: []                    # List of tags for experiment categorization
image_size: 128             # Target image size (both width and height)
fine_tune: False            # Global flag to enable fine-tuning phase
verbose: false              # Verbosity flag for logging output
version: auto               # Experiment version identifier (auto uses current timestamp)
save: true                  # Flag to enable saving of models and artifacts
seed: 42                    # Random seed for reproducibility
src_path: "/Users/leonardo/Library/CloudStorage/Box-Box/CryptoVision/Data/Images/Sources"  # Root directory for image data

# Warnings and Logging
suppress_warnings: true    # Suppress TensorFlow and other system warnings

# =====================================================
# Data Configuration
# =====================================================

# Data Splitting
test_size: 0.15            # Proportion of data to reserve for testing
validation_size: 0.15      # Proportion of data to reserve for validation
batch_size: 32             # Batch size for training and evaluation
samples_threshold: 90      # Minimum number of samples per class to include

# =====================================================
# Model Architecture Settings
# =====================================================

pretrain: "rn50v2"         # Pre-trained model backbone (options: rn50v2, rn152v2, efv2b0, efv2b1, vgg16)
architecture: "gated"      # Architectural variant; options: gated, concat, std, att
shared_dropout: 0.4        # Dropout rate for shared (common) layers
features_dropout: 0.4      # Dropout rate for feature extraction layers
shared_layer_neurons: 2048 # Number of neurons in the shared layers (e.g., 256, 512, 1024, 2048)
pooling_type: "max"        # Pooling type; options: "avg" or "max"

# =====================================================
# Compilation Settings for Initial Training
# =====================================================

lr: 0.0001                 # Learning rate for initial training
loss: "categorical_focal_crossentropy"  # Loss function to use
metrics: ["accuracy", "Precision", "Recall", "AUC"]  # Evaluation metrics
loss_weights: [1.0, 1.0, 1.0]          # Loss weights for each output (family, genus, species)

# =====================================================
# Training Settings
# =====================================================

epochs: 30                  # Number of training epochs

# Early Stopping Configuration
early_stop:
  patience: 3               # Number of epochs with no improvement before stopping
  monitor: "val_loss"       # Metric to monitor for early stopping
restore_best_weights: true  # Whether to restore the best model weights after stopping

# Learning Rate Reduction Settings
reduce_lr:
  monitor: "val_loss"       # Metric to monitor for reducing learning rate
  factor: 0.2               # Factor by which the learning rate will be reduced
  patience: 2               # Patience (in epochs) before reducing the learning rate
  min: 0.000001             # Minimum learning rate allowed

# Checkpoint Settings
checkpoint:
  monitor: "val_loss"       # Metric to monitor for saving model checkpoints
  mode: "min"               # Mode for checkpointing ('min' for loss, 'max' for accuracy, etc.)
save_best_only: true        # Save only the model with the best performance

# =====================================================
# Fine-Tuning Settings
# =====================================================
# These settings are specifically applied during the fine-tuning phase.

ft:
  model_path: "models/CVisionClassifier/CVis_BEM_320_2503.29.1518/model_ftune75_final.keras" # Path to the pre-trained model used for fine-tuning.
  epochs: 15               # Number of epochs dedicated to fine-tuning
  layers: 75               # Number of layers in the pre-trained module to keep trainable during fine-tuning
  lr: 0.00001              # Learning rate for the fine-tuning phase
  patience: 4              # Patience for early stopping during fine-tuning
  loss: "categorical_focal_crossentropy"  # Loss function for fine-tuning
  metrics: ["accuracy", "Precision", "Recall", "AUC"]  # Metrics to evaluate during fine-tuning
  loss_weights: [1.0, 1.0, 1.0]  # Loss weights during fine-tuning
  checkpoint_monitor: "val_loss"  # Metric used to determine checkpoint saving during fine-tuning
  save_best_only: true     # Only save the best model during fine-tuning
  monitor: "val_loss"        # Metric to monitor for learning rate adjustments in fine-tuning
  factor: 0.5              # Factor for reducing the learning rate during fine-tuning
  min_lr: 0.0000001        # Minimum allowed learning rate during fine-tuning